{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e54ad309",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric as tog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f1dbafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "zinc = tog.datasets.ZINC(\n",
    "    root=\"/Users/clementbarcaroli/Desktop/Projet GNN/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6a0c82",
   "metadata": {},
   "source": [
    "The task is to regress the penalized logP, or octanol-water partition coefficient, is a measure of how hydrophilic or hydrophobic a molecule is (per https://www.biotage.com/blog/what-is-the-role-of-logp-in-sample-prep-methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2800091f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/ygzb10g95l1b1v6fvr94tbv00000gn/T/ipykernel_50114/4155381171.py:3: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  train.data.y = train.data.y.float()\n",
      "/var/folders/td/ygzb10g95l1b1v6fvr94tbv00000gn/T/ipykernel_50114/4155381171.py:5: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  val.data.y = val.data.y.float()\n",
      "/var/folders/td/ygzb10g95l1b1v6fvr94tbv00000gn/T/ipykernel_50114/4155381171.py:7: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  test.data.y = test.data.y.float()\n"
     ]
    }
   ],
   "source": [
    "#y is converted because it is originally in double format, which is not well handled by pytorch\n",
    "train = tog.datasets.ZINC(root=\"data\", split=\"train\")\n",
    "train.data.y = train.data.y.float() \n",
    "val   = tog.datasets.ZINC(root=\"data\", split=\"val\")\n",
    "val.data.y = val.data.y.float()\n",
    "test  = tog.datasets.ZINC(root=\"data\", split=\"test\")\n",
    "test.data.y = test.data.y.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "192c695d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.5784])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zinc[12]\n",
    "#x=[23,1]==> the 12th molecule has 23 atoms, each with a feature vector. Therefore, we have 23 nodes.\n",
    "#edge_index = [2,50] ==> the bonds between atoms are bidirectional (indicated by 2), so 50 directed edges represent 25 bonds\n",
    "#edge_attributes = [50] ==> 50 edges \n",
    "#y=[1] ==> gives the size of the label logP (in this case 1 bc only one graph taken)\n",
    "zinc[12].y  #logP value of the 12th molecule = -2,5784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c71a360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = tog.loader.DataLoader(test, batch_size=32, shuffle=True)\n",
    "train_loader = tog.loader.DataLoader(train, batch_size=32, shuffle=True)\n",
    "val_loader = tog.loader.DataLoader(val, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29ef149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataBatch(x=[748, 1], edge_index=[2, 1608], edge_attr=[1608], y=[32], batch=[748], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[742, 1], edge_index=[2, 1598], edge_attr=[1598], y=[32], batch=[742], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[753, 1], edge_index=[2, 1624], edge_attr=[1624], y=[32], batch=[753], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[737, 1], edge_index=[2, 1588], edge_attr=[1588], y=[32], batch=[737], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[764, 1], edge_index=[2, 1646], edge_attr=[1646], y=[32], batch=[764], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[745, 1], edge_index=[2, 1602], edge_attr=[1602], y=[32], batch=[745], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[736, 1], edge_index=[2, 1558], edge_attr=[1558], y=[32], batch=[736], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[707, 1], edge_index=[2, 1512], edge_attr=[1512], y=[32], batch=[707], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[744, 1], edge_index=[2, 1592], edge_attr=[1592], y=[32], batch=[744], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[720, 1], edge_index=[2, 1550], edge_attr=[1550], y=[32], batch=[720], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[734, 1], edge_index=[2, 1572], edge_attr=[1572], y=[32], batch=[734], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[737, 1], edge_index=[2, 1584], edge_attr=[1584], y=[32], batch=[737], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[737, 1], edge_index=[2, 1578], edge_attr=[1578], y=[32], batch=[737], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[718, 1], edge_index=[2, 1558], edge_attr=[1558], y=[32], batch=[718], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[713, 1], edge_index=[2, 1532], edge_attr=[1532], y=[32], batch=[713], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[716, 1], edge_index=[2, 1542], edge_attr=[1542], y=[32], batch=[716], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[731, 1], edge_index=[2, 1560], edge_attr=[1560], y=[32], batch=[731], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[735, 1], edge_index=[2, 1566], edge_attr=[1566], y=[32], batch=[735], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[723, 1], edge_index=[2, 1546], edge_attr=[1546], y=[32], batch=[723], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[802, 1], edge_index=[2, 1730], edge_attr=[1730], y=[32], batch=[802], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[715, 1], edge_index=[2, 1536], edge_attr=[1536], y=[32], batch=[715], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[736, 1], edge_index=[2, 1582], edge_attr=[1582], y=[32], batch=[736], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[738, 1], edge_index=[2, 1580], edge_attr=[1580], y=[32], batch=[738], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[766, 1], edge_index=[2, 1654], edge_attr=[1654], y=[32], batch=[766], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[767, 1], edge_index=[2, 1640], edge_attr=[1640], y=[32], batch=[767], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[793, 1], edge_index=[2, 1716], edge_attr=[1716], y=[32], batch=[793], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[756, 1], edge_index=[2, 1626], edge_attr=[1626], y=[32], batch=[756], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[779, 1], edge_index=[2, 1676], edge_attr=[1676], y=[32], batch=[779], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[765, 1], edge_index=[2, 1656], edge_attr=[1656], y=[32], batch=[765], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[743, 1], edge_index=[2, 1592], edge_attr=[1592], y=[32], batch=[743], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[760, 1], edge_index=[2, 1630], edge_attr=[1630], y=[32], batch=[760], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[740, 1], edge_index=[2, 1592], edge_attr=[1592], y=[32], batch=[740], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[755, 1], edge_index=[2, 1632], edge_attr=[1632], y=[32], batch=[755], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[787, 1], edge_index=[2, 1710], edge_attr=[1710], y=[32], batch=[787], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[759, 1], edge_index=[2, 1642], edge_attr=[1642], y=[32], batch=[759], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[719, 1], edge_index=[2, 1542], edge_attr=[1542], y=[32], batch=[719], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[747, 1], edge_index=[2, 1622], edge_attr=[1622], y=[32], batch=[747], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[739, 1], edge_index=[2, 1578], edge_attr=[1578], y=[32], batch=[739], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[711, 1], edge_index=[2, 1526], edge_attr=[1526], y=[32], batch=[711], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[767, 1], edge_index=[2, 1664], edge_attr=[1664], y=[32], batch=[767], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[711, 1], edge_index=[2, 1516], edge_attr=[1516], y=[32], batch=[711], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[721, 1], edge_index=[2, 1548], edge_attr=[1548], y=[32], batch=[721], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[702, 1], edge_index=[2, 1502], edge_attr=[1502], y=[32], batch=[702], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[698, 1], edge_index=[2, 1498], edge_attr=[1498], y=[32], batch=[698], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[705, 1], edge_index=[2, 1512], edge_attr=[1512], y=[32], batch=[705], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[714, 1], edge_index=[2, 1530], edge_attr=[1530], y=[32], batch=[714], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[756, 1], edge_index=[2, 1626], edge_attr=[1626], y=[32], batch=[756], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[719, 1], edge_index=[2, 1552], edge_attr=[1552], y=[32], batch=[719], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[694, 1], edge_index=[2, 1486], edge_attr=[1486], y=[32], batch=[694], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[717, 1], edge_index=[2, 1550], edge_attr=[1550], y=[32], batch=[717], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[739, 1], edge_index=[2, 1590], edge_attr=[1590], y=[32], batch=[739], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[726, 1], edge_index=[2, 1558], edge_attr=[1558], y=[32], batch=[726], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[784, 1], edge_index=[2, 1696], edge_attr=[1696], y=[32], batch=[784], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[761, 1], edge_index=[2, 1636], edge_attr=[1636], y=[32], batch=[761], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[781, 1], edge_index=[2, 1692], edge_attr=[1692], y=[32], batch=[781], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[766, 1], edge_index=[2, 1660], edge_attr=[1660], y=[32], batch=[766], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[713, 1], edge_index=[2, 1532], edge_attr=[1532], y=[32], batch=[713], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[715, 1], edge_index=[2, 1532], edge_attr=[1532], y=[32], batch=[715], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[732, 1], edge_index=[2, 1566], edge_attr=[1566], y=[32], batch=[732], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[749, 1], edge_index=[2, 1630], edge_attr=[1630], y=[32], batch=[749], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[742, 1], edge_index=[2, 1598], edge_attr=[1598], y=[32], batch=[742], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[801, 1], edge_index=[2, 1730], edge_attr=[1730], y=[32], batch=[801], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[695, 1], edge_index=[2, 1488], edge_attr=[1488], y=[32], batch=[695], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[748, 1], edge_index=[2, 1618], edge_attr=[1618], y=[32], batch=[748], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[737, 1], edge_index=[2, 1584], edge_attr=[1584], y=[32], batch=[737], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[760, 1], edge_index=[2, 1634], edge_attr=[1634], y=[32], batch=[760], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[729, 1], edge_index=[2, 1556], edge_attr=[1556], y=[32], batch=[729], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[716, 1], edge_index=[2, 1528], edge_attr=[1528], y=[32], batch=[716], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[734, 1], edge_index=[2, 1580], edge_attr=[1580], y=[32], batch=[734], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[718, 1], edge_index=[2, 1552], edge_attr=[1552], y=[32], batch=[718], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[733, 1], edge_index=[2, 1586], edge_attr=[1586], y=[32], batch=[733], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[742, 1], edge_index=[2, 1594], edge_attr=[1594], y=[32], batch=[742], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[720, 1], edge_index=[2, 1542], edge_attr=[1542], y=[32], batch=[720], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[766, 1], edge_index=[2, 1656], edge_attr=[1656], y=[32], batch=[766], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[725, 1], edge_index=[2, 1562], edge_attr=[1562], y=[32], batch=[725], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[728, 1], edge_index=[2, 1560], edge_attr=[1560], y=[32], batch=[728], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[780, 1], edge_index=[2, 1690], edge_attr=[1690], y=[32], batch=[780], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[703, 1], edge_index=[2, 1506], edge_attr=[1506], y=[32], batch=[703], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[715, 1], edge_index=[2, 1530], edge_attr=[1530], y=[32], batch=[715], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[802, 1], edge_index=[2, 1742], edge_attr=[1742], y=[32], batch=[802], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[730, 1], edge_index=[2, 1570], edge_attr=[1570], y=[32], batch=[730], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[759, 1], edge_index=[2, 1642], edge_attr=[1642], y=[32], batch=[759], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[725, 1], edge_index=[2, 1562], edge_attr=[1562], y=[32], batch=[725], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[723, 1], edge_index=[2, 1550], edge_attr=[1550], y=[32], batch=[723], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[723, 1], edge_index=[2, 1554], edge_attr=[1554], y=[32], batch=[723], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[698, 1], edge_index=[2, 1492], edge_attr=[1492], y=[32], batch=[698], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[729, 1], edge_index=[2, 1556], edge_attr=[1556], y=[32], batch=[729], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[746, 1], edge_index=[2, 1620], edge_attr=[1620], y=[32], batch=[746], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[749, 1], edge_index=[2, 1604], edge_attr=[1604], y=[32], batch=[749], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[769, 1], edge_index=[2, 1654], edge_attr=[1654], y=[32], batch=[769], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[691, 1], edge_index=[2, 1470], edge_attr=[1470], y=[32], batch=[691], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[739, 1], edge_index=[2, 1580], edge_attr=[1580], y=[32], batch=[739], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[747, 1], edge_index=[2, 1600], edge_attr=[1600], y=[32], batch=[747], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[769, 1], edge_index=[2, 1668], edge_attr=[1668], y=[32], batch=[769], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[722, 1], edge_index=[2, 1544], edge_attr=[1544], y=[32], batch=[722], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[751, 1], edge_index=[2, 1616], edge_attr=[1616], y=[32], batch=[751], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[719, 1], edge_index=[2, 1532], edge_attr=[1532], y=[32], batch=[719], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[763, 1], edge_index=[2, 1646], edge_attr=[1646], y=[32], batch=[763], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[715, 1], edge_index=[2, 1534], edge_attr=[1534], y=[32], batch=[715], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[739, 1], edge_index=[2, 1588], edge_attr=[1588], y=[32], batch=[739], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[744, 1], edge_index=[2, 1604], edge_attr=[1604], y=[32], batch=[744], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[748, 1], edge_index=[2, 1608], edge_attr=[1608], y=[32], batch=[748], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[750, 1], edge_index=[2, 1606], edge_attr=[1606], y=[32], batch=[750], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[731, 1], edge_index=[2, 1564], edge_attr=[1564], y=[32], batch=[731], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[787, 1], edge_index=[2, 1706], edge_attr=[1706], y=[32], batch=[787], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[704, 1], edge_index=[2, 1506], edge_attr=[1506], y=[32], batch=[704], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[761, 1], edge_index=[2, 1636], edge_attr=[1636], y=[32], batch=[761], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[734, 1], edge_index=[2, 1568], edge_attr=[1568], y=[32], batch=[734], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[750, 1], edge_index=[2, 1634], edge_attr=[1634], y=[32], batch=[750], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[782, 1], edge_index=[2, 1696], edge_attr=[1696], y=[32], batch=[782], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[745, 1], edge_index=[2, 1616], edge_attr=[1616], y=[32], batch=[745], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[741, 1], edge_index=[2, 1578], edge_attr=[1578], y=[32], batch=[741], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[707, 1], edge_index=[2, 1518], edge_attr=[1518], y=[32], batch=[707], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[749, 1], edge_index=[2, 1608], edge_attr=[1608], y=[32], batch=[749], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[702, 1], edge_index=[2, 1504], edge_attr=[1504], y=[32], batch=[702], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[731, 1], edge_index=[2, 1552], edge_attr=[1552], y=[32], batch=[731], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[712, 1], edge_index=[2, 1524], edge_attr=[1524], y=[32], batch=[712], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[672, 1], edge_index=[2, 1438], edge_attr=[1438], y=[32], batch=[672], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[772, 1], edge_index=[2, 1660], edge_attr=[1660], y=[32], batch=[772], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[792, 1], edge_index=[2, 1704], edge_attr=[1704], y=[32], batch=[792], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[754, 1], edge_index=[2, 1632], edge_attr=[1632], y=[32], batch=[754], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[709, 1], edge_index=[2, 1508], edge_attr=[1508], y=[32], batch=[709], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[703, 1], edge_index=[2, 1518], edge_attr=[1518], y=[32], batch=[703], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[776, 1], edge_index=[2, 1676], edge_attr=[1676], y=[32], batch=[776], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[742, 1], edge_index=[2, 1592], edge_attr=[1592], y=[32], batch=[742], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[717, 1], edge_index=[2, 1550], edge_attr=[1550], y=[32], batch=[717], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[751, 1], edge_index=[2, 1608], edge_attr=[1608], y=[32], batch=[751], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[774, 1], edge_index=[2, 1676], edge_attr=[1676], y=[32], batch=[774], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[711, 1], edge_index=[2, 1520], edge_attr=[1520], y=[32], batch=[711], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[749, 1], edge_index=[2, 1608], edge_attr=[1608], y=[32], batch=[749], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[741, 1], edge_index=[2, 1584], edge_attr=[1584], y=[32], batch=[741], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[702, 1], edge_index=[2, 1500], edge_attr=[1500], y=[32], batch=[702], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[748, 1], edge_index=[2, 1620], edge_attr=[1620], y=[32], batch=[748], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[727, 1], edge_index=[2, 1562], edge_attr=[1562], y=[32], batch=[727], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[782, 1], edge_index=[2, 1682], edge_attr=[1682], y=[32], batch=[782], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[767, 1], edge_index=[2, 1646], edge_attr=[1646], y=[32], batch=[767], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[722, 1], edge_index=[2, 1552], edge_attr=[1552], y=[32], batch=[722], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[732, 1], edge_index=[2, 1572], edge_attr=[1572], y=[32], batch=[732], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[778, 1], edge_index=[2, 1674], edge_attr=[1674], y=[32], batch=[778], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[693, 1], edge_index=[2, 1480], edge_attr=[1480], y=[32], batch=[693], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[744, 1], edge_index=[2, 1588], edge_attr=[1588], y=[32], batch=[744], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[766, 1], edge_index=[2, 1646], edge_attr=[1646], y=[32], batch=[766], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[744, 1], edge_index=[2, 1592], edge_attr=[1592], y=[32], batch=[744], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[709, 1], edge_index=[2, 1514], edge_attr=[1514], y=[32], batch=[709], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[732, 1], edge_index=[2, 1578], edge_attr=[1578], y=[32], batch=[732], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[741, 1], edge_index=[2, 1594], edge_attr=[1594], y=[32], batch=[741], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[751, 1], edge_index=[2, 1622], edge_attr=[1622], y=[32], batch=[751], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[775, 1], edge_index=[2, 1680], edge_attr=[1680], y=[32], batch=[775], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[766, 1], edge_index=[2, 1654], edge_attr=[1654], y=[32], batch=[766], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[745, 1], edge_index=[2, 1598], edge_attr=[1598], y=[32], batch=[745], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[755, 1], edge_index=[2, 1624], edge_attr=[1624], y=[32], batch=[755], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[703, 1], edge_index=[2, 1512], edge_attr=[1512], y=[32], batch=[703], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[694, 1], edge_index=[2, 1466], edge_attr=[1466], y=[32], batch=[694], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[782, 1], edge_index=[2, 1692], edge_attr=[1692], y=[32], batch=[782], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[736, 1], edge_index=[2, 1582], edge_attr=[1582], y=[32], batch=[736], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[723, 1], edge_index=[2, 1550], edge_attr=[1550], y=[32], batch=[723], ptr=[33])\n",
      "32\n",
      "DataBatch(x=[161, 1], edge_index=[2, 348], edge_attr=[348], y=[8], batch=[161], ptr=[9])\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "#Example of a batch \n",
    "#Each batch contains 32 graphs except the last one of size 8\n",
    "\n",
    "for batch in test_loader:\n",
    "    print(batch)\n",
    "    print(batch.num_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a2f0c93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#To get an idea of the scale of logP, we plot its distribution in the training set.\n",
    "\n",
    "logP_values = []\n",
    "for data in train:\n",
    "    logP_values.append(data.y.item())\n",
    "logP_series = pd.Series(logP_values)\n",
    "logP_series.plot(kind='hist', bins=50, title='Distribution of logP', xlabel='logP', ylabel='Frequency')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#Values centered around 0, with a left tail rather long for a log transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044541a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ef090e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logP min (train): -62.138\n",
      "logP max (train): 4.519\n",
      "logP mean (train): -0.000\n",
      "logP std (train): 2.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/td/ygzb10g95l1b1v6fvr94tbv00000gn/T/ipykernel_50114/3397514708.py:1: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  y_train = train.data.y.float()\n"
     ]
    }
   ],
   "source": [
    "y_train = train.data.y.float()\n",
    "\n",
    "y_min = y_train.min().item()\n",
    "y_max = y_train.max().item()\n",
    "y_mean = y_train.mean().item()\n",
    "y_std = y_train.std().item()\n",
    "\n",
    "print(f\"logP min (train): {y_min:.3f}\")\n",
    "print(f\"logP max (train): {y_max:.3f}\")\n",
    "print(f\"logP mean (train): {y_mean:.3f}\")\n",
    "print(f\"logP std (train): {y_std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef5d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward needs a sampling (done automatically by torch), convolutions and at least one pooling before the final activation.\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "#2 GIN convolutions, ReLU activation of each convolution\n",
    "        self.conv1 = tog.nn.GINConv(torch.nn.Sequential(torch.nn.Linear(in_channels, 64),torch.nn.ReLU(),torch.nn.Linear(64, 64),))\n",
    "        self.conv2 = tog.nn.GINConv(torch.nn.Sequential(torch.nn.Linear(64, 64),torch.nn.ReLU(),torch.nn.Linear(64, 64),))\n",
    "        self.pooling = tog.nn.SAGPooling(64, ratio=0.5) #Not used, the model did not learn with it\n",
    "\n",
    "#Fully connected layer to perform regression on the graph-level representation\n",
    "        self.lin = torch.nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x.float(), data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        #x, edge_index, batch = self.pooling(x, edge_index, batch)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        #x, edge_index, batch = self.pooling(x, edge_index, batch)\n",
    "        x = tog.nn.global_mean_pool(x, batch)\n",
    "\n",
    "        return self.lin(x) #activation \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c171ac",
   "metadata": {},
   "source": [
    "GIN = Graph Isomorphism Network from https://arxiv.org/abs/1810.00826. It is a spatial convolution, conceived as an upgrade to the approach seen in Duvenaud et al (2015).\n",
    "global_mean_pool = pooling by taking the mean. It is a direct pooling, because there are not enough nodes per graph for hierarchical to be needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc74647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 | Loss 1.1082\n",
      "Epoch 001 | Loss 0.9802\n",
      "Epoch 002 | Loss 0.9146\n",
      "Epoch 003 | Loss 0.8737\n",
      "Epoch 004 | Loss 0.8529\n",
      "Epoch 005 | Loss 0.8340\n",
      "Epoch 006 | Loss 0.8217\n",
      "Epoch 007 | Loss 0.8144\n",
      "Epoch 008 | Loss 0.8075\n",
      "Epoch 009 | Loss 0.7998\n",
      "Epoch 010 | Loss 0.7957\n",
      "Epoch 011 | Loss 0.7903\n",
      "Epoch 012 | Loss 0.7848\n",
      "Epoch 013 | Loss 0.7816\n",
      "Epoch 014 | Loss 0.7759\n",
      "Epoch 015 | Loss 0.7700\n",
      "Epoch 016 | Loss 0.7639\n",
      "Epoch 017 | Loss 0.7604\n",
      "Epoch 018 | Loss 0.7562\n",
      "Epoch 019 | Loss 0.7534\n",
      "Epoch 020 | Loss 0.7491\n",
      "Epoch 021 | Loss 0.7478\n",
      "Epoch 022 | Loss 0.7455\n",
      "Epoch 023 | Loss 0.7442\n",
      "Epoch 024 | Loss 0.7399\n",
      "Epoch 025 | Loss 0.7379\n",
      "Epoch 026 | Loss 0.7348\n",
      "Epoch 027 | Loss 0.7351\n",
      "Epoch 028 | Loss 0.7323\n",
      "Epoch 029 | Loss 0.7309\n",
      "Epoch 030 | Loss 0.7291\n",
      "Epoch 031 | Loss 0.7269\n",
      "Epoch 032 | Loss 0.7250\n",
      "Epoch 033 | Loss 0.7245\n",
      "Epoch 034 | Loss 0.7238\n",
      "Epoch 035 | Loss 0.7213\n",
      "Epoch 036 | Loss 0.7203\n",
      "Epoch 037 | Loss 0.7204\n",
      "Epoch 038 | Loss 0.7182\n",
      "Epoch 039 | Loss 0.7160\n",
      "Epoch 040 | Loss 0.7148\n",
      "Epoch 041 | Loss 0.7136\n",
      "Epoch 042 | Loss 0.7126\n",
      "Epoch 043 | Loss 0.7108\n",
      "Epoch 044 | Loss 0.7090\n",
      "Epoch 045 | Loss 0.7086\n",
      "Epoch 046 | Loss 0.7060\n",
      "Epoch 047 | Loss 0.7031\n",
      "Epoch 048 | Loss 0.7008\n",
      "Epoch 049 | Loss 0.7001\n",
      "Epoch 050 | Loss 0.6984\n",
      "Epoch 051 | Loss 0.6964\n",
      "Epoch 052 | Loss 0.6965\n",
      "Epoch 053 | Loss 0.6948\n",
      "Epoch 054 | Loss 0.6959\n",
      "Epoch 055 | Loss 0.6927\n",
      "Epoch 056 | Loss 0.6886\n",
      "Epoch 057 | Loss 0.6876\n",
      "Epoch 058 | Loss 0.6862\n",
      "Epoch 059 | Loss 0.6857\n",
      "Epoch 060 | Loss 0.6845\n",
      "Epoch 061 | Loss 0.6822\n",
      "Epoch 062 | Loss 0.6829\n",
      "Epoch 063 | Loss 0.6813\n",
      "Epoch 064 | Loss 0.6824\n",
      "Epoch 065 | Loss 0.6807\n",
      "Epoch 066 | Loss 0.6812\n",
      "Epoch 067 | Loss 0.6779\n",
      "Epoch 068 | Loss 0.6773\n",
      "Epoch 069 | Loss 0.6780\n",
      "Epoch 070 | Loss 0.6767\n",
      "Epoch 071 | Loss 0.6752\n",
      "Epoch 072 | Loss 0.6755\n",
      "Epoch 073 | Loss 0.6745\n",
      "Epoch 074 | Loss 0.6753\n",
      "Epoch 075 | Loss 0.6739\n",
      "Epoch 076 | Loss 0.6751\n",
      "Epoch 077 | Loss 0.6733\n",
      "Epoch 078 | Loss 0.6740\n",
      "Epoch 079 | Loss 0.6726\n",
      "Epoch 080 | Loss 0.6727\n",
      "Epoch 081 | Loss 0.6726\n",
      "Epoch 082 | Loss 0.6718\n",
      "Epoch 083 | Loss 0.6720\n",
      "Epoch 084 | Loss 0.6711\n",
      "Epoch 085 | Loss 0.6709\n",
      "Epoch 086 | Loss 0.6701\n",
      "Epoch 087 | Loss 0.6704\n",
      "Epoch 088 | Loss 0.6706\n",
      "Epoch 089 | Loss 0.6697\n",
      "Epoch 090 | Loss 0.6692\n",
      "Epoch 091 | Loss 0.6694\n",
      "Epoch 092 | Loss 0.6683\n",
      "Epoch 093 | Loss 0.6686\n",
      "Epoch 094 | Loss 0.6674\n",
      "Epoch 095 | Loss 0.6674\n",
      "Epoch 096 | Loss 0.6665\n",
      "Epoch 097 | Loss 0.6667\n",
      "Epoch 098 | Loss 0.6664\n",
      "Epoch 099 | Loss 0.6660\n"
     ]
    }
   ],
   "source": [
    "#Training phase is quite long, 100 epochs used just to showcase convergence \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = GCN(train.num_node_features).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loss_fn = torch.nn.L1Loss() #We use the MAE because y is continuous\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        batch.batch = batch.batch.long()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch).squeeze(-1)   #.squeeze(-1) to remove the last dimension of size 1, which caused problems to compute the loss\n",
    "        loss = loss_fn(out, batch.y.float())\n",
    "        loss.backward() #Backpropagation\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "    print(f\"Epoch {epoch:03d} | Loss {total_loss / len(train):.4f}\") #To see the progress at each epoch in terms of MAE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0dbc70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 0.6655\n"
     ]
    }
   ],
   "source": [
    "#Now that the model is trained, we can evaluate it on the test set\n",
    "\n",
    "def evaluate(model, loader, dataset, device):\n",
    "    model.eval()\n",
    "    total_error = 0.0\n",
    "\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch).squeeze(-1)     #To remove the last dimension of size 1 which caused problems\n",
    "        error = torch.abs(out - batch.y.float()) #Absolute error\n",
    "        total_error += error.sum().item()\n",
    "\n",
    "    return total_error / len(dataset) #Same thing as before with the training phase\n",
    "\n",
    "test_mse = evaluate(model, test_loader, test, device)\n",
    "print(f\"Test MAE: {test_mse:.4f}\")\n",
    "\n",
    "#From what we saw of the logP distribution, the MAE being around 0.66 is a bit high but acceptable for a showcase\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
